{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96207a1f-4ae4-4cfa-aaab-44f6a3084ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jupyterlab in c:\\users\\farha\\anaconda3\\lib\\site-packages (4.0.11)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting qiskit\n",
      "  Downloading qiskit-1.3.2-cp39-abi3-win_amd64.whl.metadata (13 kB)\n",
      "Collecting qiskit-aqua\n",
      "  Downloading qiskit_aqua-0.9.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: networkx in c:\\users\\farha\\anaconda3\\lib\\site-packages (3.1)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in c:\\users\\farha\\anaconda3\\lib\\site-packages (from jupyterlab) (2.0.4)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\farha\\anaconda3\\lib\\site-packages (from jupyterlab) (6.29.5)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in c:\\users\\farha\\anaconda3\\lib\\site-packages (from jupyterlab) (3.1.3)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\farha\\anaconda3\\lib\\site-packages (from jupyterlab) (5.5.0)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in c:\\users\\farha\\anaconda3\\lib\\site-packages (from jupyterlab) (2.2.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in c:\\users\\farha\\anaconda3\\lib\\site-packages (from jupyterlab) (2.10.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.19.0 in c:\\users\\farha\\anaconda3\\lib\\site-packages (from jupyterlab) (2.25.1)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in c:\\users\\farha\\anaconda3\\lib\\site-packages (from jupyterlab) (0.2.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\farha\\anaconda3\\lib\\site-packages (from jupyterlab) (23.1)\n",
      "Requirement already satisfied: tornado>=6.2.0 in c:\\users\\farha\\anaconda3\\lib\\site-packages (from jupyterlab) (6.3.3)\n",
      "Requirement already satisfied: traitlets in c:\\users\\farha\\anaconda3\\lib\\site-packages (from jupyterlab) (5.7.1)\n",
      "Collecting rustworkx>=0.15.0 (from qiskit)\n",
      "  Downloading rustworkx-0.16.0-cp39-abi3-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.17 in c:\\users\\farha\\anaconda3\\lib\\site-packages (from qiskit) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5 in c:\\users\\farha\\anaconda3\\lib\\site-packages (from qiskit) (1.11.4)\n",
      "Requirement already satisfied: sympy>=1.3 in c:\\users\\farha\\anaconda3\\lib\\site-packages (from qiskit) (1.13.1)\n",
      "Requirement already satisfied: dill>=0.3 in c:\\users\\farha\\anaconda3\\lib\\site-packages (from qiskit) (0.3.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in c:\\users\\farha\\anaconda3\\lib\\site-packages (from qiskit) (2.8.2)\n",
      "Collecting stevedore>=3.0.0 (from qiskit)\n",
      "  Downloading stevedore-5.4.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\farha\\anaconda3\\lib\\site-packages (from qiskit) (4.9.0)\n",
      "Collecting symengine<0.14,>=0.11 (from qiskit)\n",
      "  Downloading symengine-0.13.0-cp311-cp311-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting qiskit-terra>=0.18.0 (from qiskit-aqua)\n",
      "  Downloading qiskit_terra-0.46.3-cp38-abi3-win_amd64.whl.metadata (13 kB)\n",
      "Collecting qiskit-ignis>=0.6.0 (from qiskit-aqua)\n",
      "  Downloading qiskit_ignis-0.7.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: psutil>=5 in c:\\users\\farha\\anaconda3\\lib\\site-packages (from qiskit-aqua) (5.9.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\farha\\anaconda3\\lib\\site-packages (from qiskit-aqua) (1.2.2)\n",
      "Collecting dlx<=1.0.4 (from qiskit-aqua)\n",
      "  Downloading dlx-1.0.4.tar.gz (5.5 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py egg_info did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [1 lines of output]\n",
      "  ERROR: Can not execute `setup.py` since setuptools is not available in the build environment.\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "pip install jupyterlab qiskit qiskit-aqua networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f515d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "from qiskit import Aer\n",
    "from qiskit.aqua import QuantumInstance\n",
    "from qiskit.aqua.algorithms import QAOA\n",
    "from qiskit.aqua.operators import WeightedPauliOperator\n",
    "from qiskit.aqua.input import EnergyInput\n",
    "from qiskit.aqua.components.optimizers import COBYLA\n",
    "\n",
    "# Step 1: Build the graph (e.g., graph of IonQ employees with edges representing interactions)\n",
    "def create_graph():\n",
    "    # Create a simple undirected graph\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Add nodes (employees)\n",
    "    G.add_nodes_from([1, 2, 3, 4, 5, 6, 7])\n",
    "    \n",
    "    # Add edges (friendships/interactions)\n",
    "    G.add_edges_from([(1, 2), (1, 3), (2, 4), (3, 4), (4, 5), (5, 6), (6, 7)])\n",
    "    \n",
    "    return G\n",
    "\n",
    "# Step 2: Create the problem Hamiltonian for the graph partitioning problem\n",
    "def create_hamiltonian(G):\n",
    "    num_nodes = len(G.nodes)\n",
    "    \n",
    "    # Initialize the cost matrix for graph partitioning (maximize cross-group edges)\n",
    "    cost_matrix = np.zeros((num_nodes, num_nodes))\n",
    "    \n",
    "    for u, v in G.edges():\n",
    "        cost_matrix[u-1][v-1] = 1  # Assign a weight to edges (cross-group edges should be maximized)\n",
    "    \n",
    "    # Construct the QUBO matrix (Binary Quadratic Unconstrained Optimization)\n",
    "    # This matrix defines the objective of maximizing the edge cut\n",
    "    qubo_matrix = np.zeros((num_nodes, num_nodes))\n",
    "    \n",
    "    for i in range(num_nodes):\n",
    "        for j in range(num_nodes):\n",
    "            qubo_matrix[i][j] = cost_matrix[i][j]\n",
    "    \n",
    "    # Construct the operator using Pauli matrices\n",
    "    pauli_list = []\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(i+1, num_nodes):\n",
    "            weight = qubo_matrix[i][j]\n",
    "            if weight != 0:\n",
    "                pauli_list.append([weight, [i, j]])\n",
    "\n",
    "    # Return the Hamiltonian operator for QAOA\n",
    "    hamiltonian = WeightedPauliOperator(paulis=pauli_list)\n",
    "    return hamiltonian\n",
    "\n",
    "# Step 3: Setup QAOA for optimization\n",
    "def run_qaoa(hamiltonian):\n",
    "    # Setup quantum backend\n",
    "    backend = Aer.get_backend('statevector_simulator')\n",
    "    \n",
    "    # Use COBYLA optimizer\n",
    "    optimizer = COBYLA(maxiter=100)\n",
    "    \n",
    "    # Setup the QAOA algorithm\n",
    "    qaoa = QAOA(hamiltonian, optimizer, p=1)  # p=1 corresponds to one layer of QAOA\n",
    "    \n",
    "    # Setup quantum instance\n",
    "    quantum_instance = QuantumInstance(backend)\n",
    "    \n",
    "    # Run the QAOA algorithm\n",
    "    result = qaoa.run(quantum_instance)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Step 4: Analyze the result to ensure balanced sizes and connectedness, and calculate scores\n",
    "def analyze_result(result, G):\n",
    "    # Decode the result (extract the binary solution)\n",
    "    solution = result['eigvecs'][0]  # Get the first eigenvector\n",
    "    print(\"Solution (binary representation of partition):\", solution)\n",
    "    \n",
    "    # Convert the binary solution to groups\n",
    "    group1 = [i+1 for i in range(len(solution)) if solution[i] == 0]\n",
    "    group2 = [i+1 for i in range(len(solution)) if solution[i] == 1]\n",
    "    \n",
    "    print(\"Group 1:\", group1)\n",
    "    print(\"Group 2:\", group2)\n",
    "    \n",
    "    # Check for roughly equal group sizes\n",
    "    size_diff = abs(len(group1) - len(group2))\n",
    "    print(\"Size Difference:\", size_diff)\n",
    "    \n",
    "    # Check for connectedness of each group\n",
    "    subgraph1 = G.subgraph(group1)\n",
    "    subgraph2 = G.subgraph(group2)\n",
    "    \n",
    "    connected1 = nx.is_connected(subgraph1)\n",
    "    connected2 = nx.is_connected(subgraph2)\n",
    "    \n",
    "    print(f\"Group 1 connected: {connected1}\")\n",
    "    print(f\"Group 2 connected: {connected2}\")\n",
    "    \n",
    "    # Calculate the cut size (number of edges between group1 and group2)\n",
    "    cut_size = 0\n",
    "    for u, v in G.edges():\n",
    "        if (u in group1 and v in group2) or (u in group2 and v in group1):\n",
    "            cut_size += 1\n",
    "    \n",
    "    # Calculate the total number of edges in the graph\n",
    "    total_edges = len(G.edges())\n",
    "    print(f\"Total edges in the graph: {total_edges}\")\n",
    "    print(f\"Cut size (number of edges between groups): {cut_size}\")\n",
    "    \n",
    "    # Calculate the \"score\" based on cut size and size balance\n",
    "    balanced_score = 1 - (size_diff / len(G.nodes))  # Normalize the balance score (0 to 1)\n",
    "    cut_score = cut_size / total_edges  # Proportion of cut edges in total edges\n",
    "    \n",
    "    print(f\"Balanced Score: {balanced_score}\")\n",
    "    print(f\"Cut Score: {cut_score}\")\n",
    "    \n",
    "    return group1, group2, connected1, connected2, size_diff, cut_size, balanced_score, cut_score\n",
    "\n",
    "# Step 5: Execute the solution\n",
    "def main():\n",
    "    G = create_graph()  # Create the graph\n",
    "    hamiltonian = create_hamiltonian(G)  # Create the Hamiltonian\n",
    "    result = run_qaoa(hamiltonian)  # Run QAOA\n",
    "    \n",
    "    # Analyze the results\n",
    "    group1, group2, connected1, connected2, size_diff, cut_size, balanced_score, cut_score = analyze_result(result, G)\n",
    "\n",
    "    if connected1 and connected2:\n",
    "        print(\"Valid partition found!\")\n",
    "    else:\n",
    "        print(\"Invalid partition: One or both groups are disconnected.\")\n",
    "\n",
    "    # Output the scores\n",
    "    print(f\"Score Summary:\")\n",
    "    print(f\"Balanced Partition Score: {balanced_score:.4f}\")\n",
    "    print(f\"Cut Size Score (cut proportion): {cut_score:.4f}\")\n",
    "    print(f\"Total Cut Size: {cut_size}\")\n",
    "    print(f\"Size Difference between groups: {size_diff}\")\n",
    "\n",
    "# Run the main function\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de5e2ca-5bc2-49c2-92e2-da005ea71653",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e32f7750-f301-4eaf-92bb-80219c610a37",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'qiskit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnx\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mqiskit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Aer\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mqiskit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maqua\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m QuantumInstance\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mqiskit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maqua\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malgorithms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m QAOA\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'qiskit'"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "from qiskit import Aer\n",
    "from qiskit.aqua import QuantumInstance\n",
    "from qiskit.aqua.algorithms import QAOA\n",
    "from qiskit.aqua.operators import WeightedPauliOperator\n",
    "from qiskit.aqua.input import EnergyInput\n",
    "from qiskit.aqua.components.optimizers import COBYLA\n",
    "\n",
    "# Build the graph \n",
    "def create_graph():\n",
    "    # Simple undirected graph\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Node\n",
    "    G.add_nodes_from([1, 2, 3, 4, 5, 6, 7])\n",
    "    \n",
    "    # Edges\n",
    "    G.add_edges_from([(1, 2), (1, 3), (2, 4), (3, 4), (4, 5), (5, 6), (6, 7)])\n",
    "    \n",
    "    return G\n",
    "\n",
    "# Problem Hamiltonian for the graph partitioning problem\n",
    "def create_hamiltonian(G):\n",
    "    num_nodes = len(G.nodes)\n",
    "    \n",
    "    # Initialize the cost matrix for graph partitioning\n",
    "    cost_matrix = np.zeros((num_nodes, num_nodes))\n",
    "    \n",
    "    for u, v in G.edges():\n",
    "        cost_matrix[u-1][v-1] = 1  # Assign a weight to edges (cross-group edges should be maximized)\n",
    "    \n",
    "    # Construct the QUBO matrix (Binary Quadratic Unconstrained Optimization)\n",
    "    qubo_matrix = np.zeros((num_nodes, num_nodes))\n",
    "    \n",
    "    for i in range(num_nodes):\n",
    "        for j in range(num_nodes):\n",
    "            qubo_matrix[i][j] = cost_matrix[i][j]\n",
    "    \n",
    "    # Construct operator using Pauli matrices\n",
    "    pauli_list = []\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(i+1, num_nodes):\n",
    "            weight = qubo_matrix[i][j]\n",
    "            if weight != 0:\n",
    "                pauli_list.append([weight, [i, j]])\n",
    "\n",
    "    # Return Hamiltonian operator for QAOA\n",
    "    hamiltonian = WeightedPauliOperator(paulis=pauli_list)\n",
    "    return hamiltonian\n",
    "\n",
    "# Step 3: Setup QAOA for optimization\n",
    "def run_qaoa(hamiltonian):\n",
    "    # Quantum backend\n",
    "    backend = Aer.get_backend('statevector_simulator')\n",
    "    \n",
    "    # COBYLA optimizer\n",
    "    optimizer = COBYLA(maxiter=100)\n",
    "    \n",
    "    # QAOA algorithm\n",
    "    qaoa = QAOA(hamiltonian, optimizer, p=1)  # p=1 corresponds to one layer of QAOA\n",
    "    \n",
    "    # Quantum instance\n",
    "    quantum_instance = QuantumInstance(backend)\n",
    "    \n",
    "    # Run the QAOA algorithm\n",
    "    result = qaoa.run(quantum_instance)\n",
    "    \n",
    "    return result\n",
    "\n",
    "#  Analyze result \n",
    "def analyze_result(result, G):\n",
    "    # extract binary solution\n",
    "    solution = result['eigvecs'][0]  # Get the first eigenvector\n",
    "    print(\"Solution (binary representation of partition):\", solution)\n",
    "    \n",
    "    # Convert binary solution to groups\n",
    "    group1 = [i+1 for i in range(len(solution)) if solution[i] == 0]\n",
    "    group2 = [i+1 for i in range(len(solution)) if solution[i] == 1]\n",
    "    \n",
    "    print(\"Group 1:\", group1)\n",
    "    print(\"Group 2:\", group2)\n",
    "    \n",
    "    # Check roughly equal group sizes\n",
    "    size_diff = abs(len(group1) - len(group2))\n",
    "    print(\"Size Difference:\", size_diff)\n",
    "    \n",
    "    # Check connectedness\n",
    "    subgraph1 = G.subgraph(group1)\n",
    "    subgraph2 = G.subgraph(group2)\n",
    "    \n",
    "    connected1 = nx.is_connected(subgraph1)\n",
    "    connected2 = nx.is_connected(subgraph2)\n",
    "    \n",
    "    print(f\"Group 1 connected: {connected1}\")\n",
    "    print(f\"Group 2 connected: {connected2}\")\n",
    "    \n",
    "    return group1, group2, connected1, connected2\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    G = create_graph()  # Create the graph\n",
    "    hamiltonian = create_hamiltonian(G)  # Create the Hamiltonian\n",
    "    result = run_qaoa(hamiltonian)  # Run QAOA\n",
    "    \n",
    "    # Analyze the results\n",
    "    group1, group2, connected1, connected2 = analyze_result(result, G)\n",
    "\n",
    "    if connected1 and connected2:\n",
    "        print(\"Valid partition found!\")\n",
    "    else:\n",
    "        print(\"Invalid partition: One or both groups are disconnected.\")\n",
    "\n",
    "# Run the main function\n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
